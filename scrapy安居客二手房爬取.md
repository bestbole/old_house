# scrapy安居客二手房爬取

最近没什么项目，博主准备对以前的项目做下整理。这个项目是作为《全国二手房数据分析》的数据源的爬虫项目。本项目是scrapy完成，利用mysql实现了分布式（一般都是和redies搭配，但博主现在不会。哈哈^_^）。主要思想是将各省市的起始url储存起来，各爬虫到mysql取url。

其网页结构是这样的。城市－>区县－>地点，如：北京－>东城－>东直门。博主先通过http://www.anjuke.com/sy-city.html进入各城市页面，在进入区县界面，再在区县界面得到按地点划分的二手房页面的url，存入数据库。每个url对应一个status表示未爬取、已爬取和正在爬取，防止中断后爬虫不可恢复。各节点取数据库中url进行爬取，分析“next”按钮是否存在，判断是否爬完，爬完后再取url。为了不重复使用url，在数据库中用一个表当作锁来实现各节点间通信。

